{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mido\n",
        "!pip install music21\n",
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuC3rGLbjayG",
        "outputId": "29554833-dc53-4b0c-8d08-7c653a366325"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=ed3ead0aaad5dab2e574b823e4da9f665dda0151c8fba4a049e7690626509bd3\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from mido import MidiFile\n",
        "import IPython\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "import keras.layers as L\n",
        "import keras.models as M\n",
        "import keras\n",
        "from keras.layers import SimpleRNN,LSTM,GRU\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Input, Concatenate, Dropout, LSTM, Conv2DTranspose, Conv2D, LeakyReLU, GlobalMaxPooling2D, Reshape, Flatten, BatchNormalization, Embedding\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "# from keras.layers.embeddings import Embedding\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, SparseCategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import RMSprop, Adam\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from IPython import *\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from numpy.random import choice\n",
        "\n",
        "from mido import Message, MidiFile, MidiTrack\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, StructType, StructField, IntegerType\n",
        "from mido import MidiFile\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import ArrayType, StructType, StructField, IntegerType, StringType\n"
      ],
      "metadata": {
        "id": "vRNnEm5OjfC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "key_notes = {\n",
        "    'Cb': 59,\n",
        "    'C': 60,\n",
        "    'C#': 61,\n",
        "    'Db': 61,\n",
        "    'D': 62,\n",
        "    'D#': 63,\n",
        "    'Eb': 63,\n",
        "    'E': 64,\n",
        "    'F': 65,\n",
        "    'F#': 66,\n",
        "    'Gb': 66,\n",
        "    'G': 67,\n",
        "    'G#': 68,\n",
        "    'Ab': 68,\n",
        "    'A': 69,\n",
        "    'A#': 70,\n",
        "    'Bb': 70,\n",
        "    'B': 71\n",
        "}"
      ],
      "metadata": {
        "id": "JAlayvl3job0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "# Read the CSV file\n",
        "data = spark.read.csv('gs://cs649project/CS649Data/musicnet_metadata.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "data.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHzhLgypjqSE",
        "outputId": "cadb39dc-0bea-48dc-d84d-586e97457ce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----+--------+--------------------+--------------------+-------------+----------------+--------------------+------------+-------+\n",
            "|  id|composer|         composition|            movement|     ensemble|          source|         transcriber|catalog_name|seconds|\n",
            "+----+--------+--------------------+--------------------+-------------+----------------+--------------------+------------+-------+\n",
            "|1727|Schubert|Piano Quintet in ...|          2. Andante|Piano Quintet|European Archive|http://tirolmusic...|       OP114|    447|\n",
            "|1728|Schubert|Piano Quintet in ...|  3. Scherzo: Presto|Piano Quintet|European Archive|http://tirolmusic...|       OP114|    251|\n",
            "|1729|Schubert|Piano Quintet in ...|4. Andantino - Al...|Piano Quintet|European Archive|http://tirolmusic...|       OP114|    444|\n",
            "|1730|Schubert|Piano Quintet in ...|   5. Allegro giusto|Piano Quintet|European Archive|http://tirolmusic...|       OP114|    368|\n",
            "|1733|Schubert|Piano Sonata in A...|        2. Andantino|   Solo Piano|        Museopen|   Segundo G. Yogore|        D959|    546|\n",
            "|1734|Schubert|Piano Sonata in A...|3. Scherzo. Alleg...|   Solo Piano|        Museopen|   Segundo G. Yogore|        D959|    325|\n",
            "|1735|Schubert|Piano Sonata in A...|4. Rondo. Allegretto|   Solo Piano|        Museopen|   Segundo G. Yogore|        D959|    714|\n",
            "|1739|Schubert|Piano Trio in B-f...|4. Rondo. Allegro...|   Piano Trio|European Archive|        harfesoft.de|        OP99|    490|\n",
            "|1742|Schubert|String Quintet in...|           2. Adagio|Viola Quintet|European Archive|        harfesoft.de|       OP163|    924|\n",
            "|1749|Schubert|Piano Sonata in A...|         1. Moderato|   Solo Piano|        Museopen|   Segundo G. Yogore|        D845|    696|\n",
            "|1750|Schubert|Piano Sonata in A...|2. Andante poco m...|   Solo Piano|        Museopen|   Segundo G. Yogore|        D845|    784|\n",
            "|1751|Schubert|Piano Sonata in A...|3. Scherzo. Alleg...|   Solo Piano|        Museopen|   Segundo G. Yogore|        D845|    475|\n",
            "|1752|Schubert|Piano Sonata in A...|4. Rondo. Allegro...|   Solo Piano|        Museopen|   Segundo G. Yogore|        D845|    362|\n",
            "|1755|Schubert|Piano Sonata in A...|          2. Andante|   Solo Piano|        Museopen|   Segundo G. Yogore|        D784|    229|\n",
            "|1756|Schubert|Piano Sonata in A...|   3. Allegro vivace|   Solo Piano|        Museopen|   Segundo G. Yogore|        D784|    371|\n",
            "|1757|Schubert|Piano Sonata in C...|          1. Allegro|   Solo Piano|        Museopen|Martin Charles Bu...|        D958|    710|\n",
            "|1758|Schubert|Piano Sonata in C...|           2. Adagio|   Solo Piano|        Museopen|Martin Charles Bu...|        D958|    468|\n",
            "|1759|Schubert|Piano Sonata in C...|3. Menuetto and Trio|   Solo Piano|        Museopen|Martin Charles Bu...|        D958|    194|\n",
            "|1760|Schubert|Piano Sonata in C...|          4. Allegro|   Solo Piano|        Museopen|Martin Charles Bu...|        D958|    655|\n",
            "|1763|Schubert|        4 Impromptus|1. Impromptu in F...|   Solo Piano|Charlie Albright|  Jeruen Espino Dery|       OP142|    600|\n",
            "+----+--------+--------------------+--------------------+-------------+----------------+--------------------+------------+-------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the MIDI files directory\n",
        "midi_files_dir = 'gs://cs649project/CS649Data/musicnet_midis/musicnet_midis/Beethoven/'\n",
        "\n",
        "beethoven_midi_tracks = {}\n",
        "n = 100\n",
        "name = None\n",
        "\n",
        "for m in range(n):\n",
        "    # Read the MIDI file\n",
        "    midi_path = os.path.join(midi_files_dir, os.listdir(midi_files_dir)[m])\n",
        "    mid = MidiFile(midi_path, clip=True)\n",
        "\n",
        "    # Process each track in the MIDI file\n",
        "    for j in range(len(mid.tracks)):\n",
        "        if j == 0:\n",
        "            name = mid.tracks[j].name + ': '\n",
        "        else:\n",
        "            beethoven_midi_tracks[name + mid.tracks[j].name] = mid.tracks[j]\n",
        "\n",
        "# Convert the dictionary to a DataFrame\n",
        "beethoven_midi_tracks_df = spark.createDataFrame(list(beethoven_midi_tracks.items()), ['track_name', 'track_data'])\n",
        "\n",
        "# Show the DataFrame\n",
        "beethoven_midi_tracks_df.show()"
      ],
      "metadata": {
        "id": "gswVpVErjq1v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_key(s):\n",
        "    k = None\n",
        "    if 'key' in s:\n",
        "        k = s[33:35]\n",
        "        if k[-1] == \"m\" or k[-1] == \"'\":\n",
        "            k = k[:-1]\n",
        "    return k\n",
        "\n",
        "def parse_notes(track):\n",
        "    key = 'C'\n",
        "    tunes = []\n",
        "    new_tune = []\n",
        "    note_dict = {}\n",
        "    for i in track:\n",
        "        if i.is_meta:\n",
        "            new_key = get_key(str(i))\n",
        "            if new_key is not None:\n",
        "                key = new_key\n",
        "            if len(tunes) > 0:\n",
        "                tunes.append(new_tune)\n",
        "                new_tune = []\n",
        "        elif i.type == 'note_on' or i.type == 'note_off':\n",
        "            if i.type == 'note_on' and i.dict()['velocity'] > 0 and i.dict()['time'] > 0:\n",
        "                note_dict['time'] = i.dict()['time']\n",
        "                note_dict['note'] = i.dict()['note']\n",
        "                note_dict['velocity'] = i.dict()['velocity']\n",
        "                note_dict['channel'] = i.dict()['channel']\n",
        "            elif i.type == 'note_off' or i.type == 'note_on' and i.dict()['velocity'] == 0:\n",
        "                if note_dict:\n",
        "                    note_dict['pause'] = i.dict()['time']\n",
        "                    note_dict['key'] = key\n",
        "                    new_tune.append(note_dict)\n",
        "                    note_dict = {}\n",
        "    tunes.append(new_tune)\n",
        "    return tunes"
      ],
      "metadata": {
        "id": "EcTNq-ZAjq36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the MIDI file\n",
        "midi_file_path = 'gs://cs649project/CS649Data/musicnet_midis/musicnet_midis/Beethoven/'\n",
        "\n",
        "# Read the MIDI file and get the tracks\n",
        "midi = MidiFile(midi_file_path)\n",
        "tracks = midi.tracks\n",
        "\n",
        "# Convert the parse_notes function to a UDF\n",
        "parse_notes_udf = udf(parse_notes, ArrayType(ArrayType(StructType([\n",
        "    StructField(\"time\", IntegerType()),\n",
        "    StructField(\"note\", IntegerType()),\n",
        "    StructField(\"velocity\", IntegerType()),\n",
        "    StructField(\"channel\", IntegerType()),\n",
        "    StructField(\"pause\", IntegerType()),\n",
        "    StructField(\"key\", StringType())\n",
        "]))))\n",
        "\n",
        "# Process each track and create a DataFrame\n",
        "track_data = []\n",
        "for track in tracks:\n",
        "    track_data.append(parse_notes(track))\n",
        "track_df = spark.createDataFrame(track_data, StringType())\n",
        "\n",
        "# Show the track DataFrame\n",
        "track_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "v30GhIwajq6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def various(notes):\n",
        "    flag = True\n",
        "    for i in range(8, len(notes)):\n",
        "        flag = len(set(notes[i-8:i])) > 2\n",
        "        if not flag:\n",
        "            break\n",
        "    return flag"
      ],
      "metadata": {
        "id": "AXIN496qknmw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "various_udf = udf(various, IntegerType())\n",
        "\n",
        "# Convert tunes to a Spark DataFrame\n",
        "tunes_df = spark.createDataFrame(tunes)\n",
        "\n",
        "# Apply the parse_notes function to the tracks\n",
        "tunes_df = tunes_df.selectExpr(\"parse_notes(track) as notes\")\n",
        "\n",
        "# Filter and create X and y DataFrames\n",
        "X_df = tunes_df.filter(various_udf(\"notes\")).selectExpr(\"explode(notes) as note\").select(\"note.*\")\n",
        "y_df = X_df.selectExpr(\"lead(time) over (order by time) as next_time\", \"lead(note) over (order by time) as next_note\", \"lead(velocity) over (order by time) as next_velocity\")\n",
        "\n",
        "# Convert X and y DataFrames to numpy arrays\n",
        "X = np.array(X_df.collect())\n",
        "y = np.array(y_df.collect())\n",
        "\n",
        "# Convert X and y arrays to integers\n",
        "X = X.astype(int)\n",
        "y = y.astype(int)"
      ],
      "metadata": {
        "id": "5n6Q6A-nkyBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_rdd = sc.parallelize(X)\n",
        "y_rdd = sc.parallelize(y)\n",
        "\n",
        "#Store extracted features into a pickel file\n",
        "import pickle\n",
        "\n",
        "\n",
        "# Store data (serialize)\n",
        "with open('X_rdd.pickle', 'wb') as handle:\n",
        "    pickle.dump(X_rdd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "with open('y_rdd.pickle', 'wb') as handle:\n",
        "    pickle.dump(y_rdd, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "#The code loops over the tunes and extracts phrases of\n",
        "# length defined by the ”phrase len” variable (in this case, 60).\n",
        "# It checks the diversity of notes within the phrase using the\n",
        "# ‘various(notes)‘ function. If the diversity condition is met,\n",
        "# the note, duration, and velocity data for the phrase are ex-\n",
        "# tracted and added to the ‘X‘ list, while the next note infor-\n",
        "# mation is added to the ‘y‘ list"
      ],
      "metadata": {
        "id": "820fRRLrlnHd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}